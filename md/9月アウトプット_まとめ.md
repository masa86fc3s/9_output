## 9月アウトプット

- sshのポート番号の指定も無しにする
インスタンス作成時に、セキュリティの観点からパブリックipの無効化
（本来ならこれで進めた後に、VPCポイントを設定してsessionmanagerに接続するのですが、今回は練習用でipを無効かしないで進めます）
**理由**

- Session Manager 経由で接続する場合、EC2 に パブリックIP は不要 です。
- 接続は AWS の内部サービス経由で行われるため、インターネット経由ではありません。
- セキュリティの観点からも、パブリックIP を持たないほうが安全です。
- 外部から直接アクセスされるリスクがなくなります。

---

sesseion managerからamazon linuxのインスタンスに入ることに成功。
ここでec2インスタンス立ち上げの時に付与したロールにs3　readonlyポリシーを追加することで、インスタンス内でs3の保存してあるデータを見ることが可能になる。

- ここでさらに書き込みの権限を加えるとec2からs3にデータを保存させることができる。ただし、ssm-userというユーザーで接続しないと権限がないため、cd /home/ssm-userで移動してからファイルを作成したのち、
aws s3 cp /home/ssm-user/test.txt s3://<バケット名>/folder1/
で作成したファイルをコピーが可能。




その場合のおすすめ構成

## S3 に新規ファイルアップロード

- 例: purchases_2025-09-01.csv

Lambda (トリガー役)

S3 にアップロードされたことを検知

Glue Job を起動するだけ（前処理は不要でも可）

Glue Job

1つのファイルを読み込む

欠損値処理・列の整形・必要なら結合処理（マスタデータがある場合など）

加工済みデータを S3 に保存（例: processed/2025/09/01/purchases.parquet）

Athena

processed バケットをクエリ対象にする

欲しい行・列だけ抽出

並び替えや集計もここで SQL で完結


* cloud formationでs3,ec2,lamda,glue,athenaのセットアップまで行ったが、cloud formationでの立ち上げ時にはs3,lamda,dynamodbなど最低限のサービスだけでは良いのではト気づいた。

* その後インフォマティカで、cloud formation,lamda,glueとかにした方が良いのではと思う。(lamdaとかの中身はその都度変更される場合があるのでcloud formationに記載せず、外部での作成の方が良いと判断した。)

* dynamodbを使用するため、s3,lamda,dynamodbをaws samでスクリプトを記入してみる。（扱えるリソースが少なくなる代わりにコードが短くすむのがcloud formationトの違い）