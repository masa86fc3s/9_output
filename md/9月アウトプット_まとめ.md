## 9月アウトプット

- sshのポート番号の指定も無しにする
インスタンス作成時に、セキュリティの観点からパブリックipの無効化
（本来ならこれで進めた後に、VPCポイントを設定してsessionmanagerに接続するのですが、今回は練習用でipを無効かしないで進めます）
**理由**

- Session Manager 経由で接続する場合、EC2 に パブリックIP は不要 です。
- 接続は AWS の内部サービス経由で行われるため、インターネット経由ではありません。
- セキュリティの観点からも、パブリックIP を持たないほうが安全です。
- 外部から直接アクセスされるリスクがなくなります。

---

sesseion managerからamazon linuxのインスタンスに入ることに成功。
ここでec2インスタンス立ち上げの時に付与したロールにs3　readonlyポリシーを追加することで、インスタンス内でs3の保存してあるデータを見ることが可能になる。

- ここでさらに書き込みの権限を加えるとec2からs3にデータを保存させることができる。ただし、ssm-userというユーザーで接続しないと権限がないため、cd /home/ssm-userで移動してからファイルを作成したのち、
aws s3 cp /home/ssm-user/test.txt s3://<バケット名>/folder1/
で作成したファイルをコピーが可能。




その場合のおすすめ構成

## S3 に新規ファイルアップロード

- 例: purchases_2025-09-01.csv

Lambda (トリガー役)

S3 にアップロードされたことを検知

Glue Job を起動するだけ（前処理は不要でも可）

Glue Job

1つのファイルを読み込む

欠損値処理・列の整形・必要なら結合処理（マスタデータがある場合など）

加工済みデータを S3 に保存（例: processed/2025/09/01/purchases.parquet）

Athena

processed バケットをクエリ対象にする

欲しい行・列だけ抽出

並び替えや集計もここで SQL で完結


* cloud formationでs3,ec2,lamda,glue,athenaのセットアップまで行ったが、cloud formationでの立ち上げ時にはs3,lamda,dynamodbなど最低限のサービスだけでは良いのではト気づいた。

* その後インフォマティカで、cloud formation,lamda,glueとかにした方が良いのではと思う。(lamdaとかの中身はその都度変更される場合があるのでcloud formationに記載せず、外部での作成の方が良いと判断した。)

* dynamodbを使用するため、s3,lamda,dynamodbをaws samでスクリプトを記入してみる。（扱えるリソースが少なくなる代わりにコードが短くすむのがcloud formationトの違い）

* デプロイする際に循環依存が発生したのでそれを解消するためにポリシーｎ付与に注意した
1. 循環依存が起きていた理由

CloudFormation は リソース間の依存関係 を自動で判断して順番に作成します。

あなたの最初のテンプレートでは：

MyLambda の IAM ポリシーで !Ref MyBucket を直接参照

同時に MyLambda イベントで !Ref MyBucket を参照

→ CloudFormation はこう判断しました：

MyBucket を作る → MyLambda を作る → MyLambdaRole (IAM) が MyBucket に依存 → MyLambda を作る


つまり バケットと Lambda とそのロールでお互い依存している状態 になり、循環依存として失敗。

2. 解決した方法

循環依存を回避するために：

IAM ポリシーで参照するバケット名を文字列化

BucketName: !Sub "${AWS::StackName}-bucket-${AWS::AccountId}-${AWS::Region}"


こうすることで、CloudFormation は IAM ロール作成時に「まだバケットができていなくても名前だけでOK」と判断できる。

Lambda イベントでは !Ref MyBucket を使う（実際の ARN が必要な部分なので OK）

3. ポイントまとめ

Lambda + S3 + IAM ポリシー の組み合わせは、CloudFormation で循環依存になりやすい

IAM ポリシーでのリソース参照を文字列化 すると循環依存を避けられる

Lambda イベントはバケットのリファレンスを使ってもOK（作成順序の問題はない）

* saas_api(今回は促成で作成したcsvファイルを使用した)
をつかってさっきの流れを再現すると、lamdaにあるadd.py(s3に保存されたらdynamodbに保存するファイル→とlamdaからsaas_apiを呼び出すファイルの二つがあり、lamdaでテストを行うとsaasのおファイルが起動して、s3にデータが保存される。そしてその保存されたタイミングでトリガーが発動して、lamdaからdynamodbにデータが保存される。)